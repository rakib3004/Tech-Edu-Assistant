<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Artificial Intelligence</title>
  <link rel="stylesheet" type="text/css" href="../../css/SubjectStyle.css">

</head>

<body bgcolor = "#00FA9A">
<h3><ul>
  <li class="web"><a class="white" href="../SubType4/ArtificialIntelligence.html">Topics</a></li>
  <li class="web"><a class="white" href="../VideoLink4/ArtificialIntelligence.html">Video Tutorials</a></li>
  <li class="web"><a class="white" href="../Pdf4/ArtificialIntelligence.html">Slides</a></li>
  <li class="web"><a class="white" href="../Link4/ArtificialIntelligence.html">Links</a></li>
</ul></h3><br><br>

<h1 class="headlines">Artificial Intelligence</h1>
<br>
<p><b><u>Course Outline:</u> </b>Intelligent Agents and their Environments - The concept of a Rational Agent,
  Specifying the Task environment (PEAS description), Different characteristics of environments
  (Fully vs Partially observable, Static vs Dynamic, Episodic vs Sequential etc.) and Different types
  of agents (Reflex, Goal-based, Utility-based etc.),Search - Formulating a search problem ,
  Uninformed Search strategies: BFS, DFS, DLS, ID-DFS, their working principles, complexities,
  relative advantages and disadvantages, Informed (heuristic) Search strategies: Greedy Best-first
  search, A* search: Working principle, Characteristics of heuristics (admissibility and consistency),
  Proof of A*’s optimality, Local search: Hill Climbing, Searching with non-deterministic actions:
  AND-OR search trees and Searching with partial observability: Belief state-space search,
  Adversarial Search - Formulation of a Game tree, The minimax algorithm, Alpha-Beta pruning: Its
  rationale, working principle and Additional techniques such as Move ordering and Search cut-off,
  Probabilistic Reasoning - Bayes’ rule and its uses, Bayesian Network: Building a Bayes-net and
  making inference from it, Markov Chains and Hidden Markov Models: Transition and Sensor
  models, Building and HMM, applications of HMM, Inference in temporal models: Filtering,
  Prediction, Most Likely explanations (Viterbi algorithm) etc. and Particle Filters: basic working
  principle, Making Decisions - Decision theory and Utility theory: Lottery, Utility functions,
  Maximum Expected Utility principle, Constraints of Utility (Orderability, Transitivity etc) and
  Markov Decision Processes: Policies, Rewards, Optimal policies and the Utility of States, Value
  Iteration, Supervised Learning - Basic concepts of classification and supervised learning: Training
  set, Test set, Overfitting, Underfitting etc., Decision trees: Basic understanding, Learning a
  Decision tree through entropy calculation, Nearest Neighbor classifier: Basic working principle,

  Relative advantages and disadvantages, Naive Bayes classifier: Basic working principle,
  Calculating classification procedures, Relative advantages and disadvantages, Artificial Neural
  Network: Basic working principle, Basic structure and calculation of a perceptron, Basics of
  backpropagation algorithm and Support Vector Machines: Basic working principle, Unsupervised
  Learning (Clustering) - Basic concepts and applications of Clustering, Different types of Clustering:
  Partitional vs. Hierarchical, Exclusive vs Overlapping vs Fuzzy, Complete vs Partial, K-means
  Clustering: Basic working principle, characteristics, advantages, disadvantages, Agglomerative
  Hierarchical Clustering: Basic concepts, Representations (Dendrograms and Nested cluster
  diagrams), Different techniques to define cluster proximity: Single link, Complete link, Group
  average, Centroid method, their relative advantages and disadvantages and DBSCAN: Basic
  principle and applications, Classification of points (Core, Border and Noise), Reinforcement
  Learning - Understanding basics of Reinforcement Learning: MDPs, Policies, Rewards, Utilities
  etc., Passive and Active Reinforcement Learning, Exploration and Exploitation, Adaptive Dynamic
  Programming, Temporal Difference Learning and Q-Learning.</p><br>
</body>
</html>
